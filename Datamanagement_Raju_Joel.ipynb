{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install redis\n",
    "#!pip install mysql-connector-python \n",
    "#!pip install pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tweepy\n",
    "import sys\n",
    "import mysql.connector \n",
    "import pymongo\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "import redis\n",
    "import fontstyle\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming data from Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckey ='e3OLPfNMEIsBXc22Rw8TpmXaw'\n",
    "csec ='iofJJbpiC9nAPnFHpKpfGh7yVRUXlbXQuVxRhzRiLd2cqSIXTl'\n",
    "akey ='1363132021053227013-CXxuCEIzH3foO7AY8DWPnLEfi0Zzdp'\n",
    "asec ='kqnwucwfUeVmlioUvTJcCR0Hvocie4nVTyzDLTQPUfggk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(ckey, csec)\n",
    "auth.set_access_token(akey, asec)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print(\"Authentication OK\")\n",
    "except:\n",
    "    print(\"Error during authentication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = 0\n",
    "tweet_max = 11000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StdOutListener(tweepy.StreamListener):\n",
    "    dummy = 0\n",
    "    tweet_max = 11000\n",
    "    def on_data(self, data):\n",
    "        if self.dummy<self.tweet_max:\n",
    "            if self.dummy==0:\n",
    "                print(\"[\")\n",
    "            print (data)\n",
    "            if self.dummy!=(self.tweet_max-1):\n",
    "                print(\",\")\n",
    "            self.dummy+=1\n",
    "            return True\n",
    "        else:\n",
    "            print(\"]\")\n",
    "            return False\n",
    "        \n",
    "    def on_error(self, status):\n",
    "        print (status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Printed output directly to the JSON file \n",
    "default_stdout = sys.stdout\n",
    "\n",
    "sys.stdout = open('04.25.2020 tweets_5.json', 'w')\n",
    "tweets_listener = StdOutListener()\n",
    "stream = tweepy.Stream(api.auth, tweets_listener)\n",
    "stream.filter(track=[\"#doge\",\"#dogecoin\",\"#bitcoin\",\"#BTC\"], languages=[\"en\"])\n",
    "\n",
    "sys.stdout = default_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_chk = open(r'04.25.2020 tweets_5.json',\"r\")\n",
    "tweets_json = json.load(tweets_chk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating SQL DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection success\n"
     ]
    }
   ],
   "source": [
    "userdb = mysql.connector.connect(host=\"localhost\",user=\"root\",passwd=\"raju437@.\", database =\"user\")\n",
    "\n",
    "if(userdb):\n",
    "    print(\"Connection success\")\n",
    "else:\n",
    "    print(\"Connection failed\")\n",
    "    \n",
    "cursor = userdb.cursor(buffered = True)\n",
    "\n",
    "\n",
    "cursor.execute(\"CREATE TABLE user (\\\n",
    "               user_id       CHAR(255),\\\n",
    "               user_name     CHAR(255),\\\n",
    "               handle        CHAR(255),\\\n",
    "               description   VARCHAR(500),\\\n",
    "              followers     BIGINT,\\\n",
    "               statuses      INT,\\\n",
    "               created_date  DATETIME,\\\n",
    "               verified      CHAR(5),\\\n",
    "               friends       INT,\\\n",
    "               favourites    INT,\\\n",
    "               protected     CHAR(50),\\\n",
    "               INDEX (user_name) )\")  \n",
    "#cursor.execute('drop table user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating MongoDB collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "tweets_db = client[\"tweet_db\"]\n",
    "#tweets_col.drop()\n",
    "tweets_col = tweets_db[\"tweets_col\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data and Pushing data into MySQL and MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in tweets_json:\n",
    "    \n",
    "    ###Starting with SQL insertion\n",
    "    user = record['user']\n",
    "    inp = [user['id_str'],user['name'], user['screen_name'],user['description'], user['followers_count'], \n",
    "                  user['statuses_count'], user['verified'],user['created_at'],user['friends_count'],user['favourites_count'],user['protected']]\n",
    "    \n",
    "    #Cleaning commas from User name and Description \n",
    "    inp[1] =  re.sub(\"'\",\"\",inp[1])\n",
    "    if inp[3] is not None:\n",
    "        inp[3] =  re.sub(\"'\",\"\",inp[3])\n",
    "        \n",
    "    #Converting tweepy created_date to datetime format     \n",
    "    inp[7] = datetime.strftime(datetime.strptime(inp[7],'%a %b %d %H:%M:%S +0000 %Y'), '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    \n",
    "    #Updating the user information for the users who are already present in the user data base\n",
    "    cursor.execute(\"select user_id from user where user_id ='{}'\".format(inp[0]))\n",
    "\n",
    "    result = cursor.fetchone()\n",
    "    if result:\n",
    "        query = \"UPDATE user SET description = '{}',followers= {},statuses= {},verified= '{}',friends={},favourites ={},protected='{}' WHERE user_id  = '{}'\".format(inp[3],inp[4],inp[5],inp[6],inp[8],inp[9],inp[10],inp[0])\n",
    "    else:\n",
    "        query = (\"INSERT INTO user (user_id, user_name, handle,description,followers,statuses,verified,created_date,friends,favourites,protected)\" \n",
    "             \"VALUES ('{}','{}','{}','{}',{},{},'{}','{}',{},{},'{}');\".format(*inp))\n",
    "    \n",
    "    cursor.execute(query)  \n",
    "    \n",
    "    \n",
    "    #MongoDB insertion\n",
    "    #Getting hashtags from the extended tweet if the original tweet is truncated \n",
    "    entities =[]\n",
    "    if record['truncated'] == False:\n",
    "        text = record['text']\n",
    "        for i in record['entities']['hashtags']:\n",
    "            entities.append(i['text'])\n",
    "    else:\n",
    "        text = record['extended_tweet']['full_text']\n",
    "        for i in record['extended_tweet']['entities']['hashtags']:\n",
    "            entities.append(i['text']) \n",
    "    \n",
    "    try: #If the first 2 words of the tweet is RT but it is not actually retweet\n",
    "        if record['text'][0:2] =='RT':\n",
    "            retweet =\"Y\"\n",
    "        #Getting hashtags and hashtags from the retweeted object\n",
    "            rt_entities =[]\n",
    "            if record['retweeted_status']['truncated'] == False:\n",
    "                rt_text = record['retweeted_status']['text'] \n",
    "\n",
    "                for i in record['retweeted_status']['entities']['hashtags']:\n",
    "                    rt_entities.append(i['text'])\n",
    "            else:\n",
    "                rt_text = record['retweeted_status']['extended_tweet']['full_text']\n",
    "\n",
    "                for i in record['retweeted_status']['extended_tweet']['entities']['hashtags']:\n",
    "                     rt_entities.append(i['text'])\n",
    "        else:\n",
    "            retweet =\"N\"\n",
    "            rt_text = None\n",
    "            rt_entities = None\n",
    "    except:\n",
    "        retweet =\"N\"\n",
    "        rt_text = None\n",
    "        rt_entities = None\n",
    "    \n",
    "        \n",
    "    time = datetime.strftime(datetime.strptime(record['created_at'],'%a %b %d %H:%M:%S +0000 %Y'), '%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "    mydict = {\"tweet_id\":record['id_str'],\"time\":time,\"user_id\":record['user']['id_str'],\"handle\":record['user']['screen_name'],\n",
    "              \"followers\":record['user']['followers_count'],\"likes\":record['favorite_count'],\"hash_orig\":entities,\"hash_rtwt\":rt_entities,\"retweet\":retweet,\"text\":text,\n",
    "             \"rtwt_text\":rt_text }\n",
    "\n",
    "    tweets_col.insert_one(mydict)\n",
    "\n",
    "tweets_col.create_index(\"followers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7386, 7386)\n"
     ]
    }
   ],
   "source": [
    "userdb.commit()\n",
    "\n",
    "query  = \"select count(distinct user_id), count(user_id) from user;\"\n",
    "cursor.execute(query)\n",
    "result = cursor.fetchall()\n",
    "for x in result:\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating Redis connection for caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = redis.StrictRedis(host='127.0.0.1', port=6379,charset=\"utf-8\", decode_responses=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching data for 4 most famous hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajuk\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:28: DeprecationWarning: Redis.hmset() is deprecated. Use Redis.hset() instead.\n"
     ]
    }
   ],
   "source": [
    "hashtags = [\"dogecoin\", \"doge\", \"bitcoin\", \"btc\"] \n",
    "\n",
    "for m in hashtags:\n",
    "    myquery = {\"$or\":[{ \"hash_orig\": { \"$elemMatch\": {\"$eq\":m} } },{ \"hash_rtwt\": { \"$elemMatch\": {\"$eq\":m} } }]}\n",
    "    mydoc = tweets_col.find(myquery).sort(\"followers\",-1)\n",
    "\n",
    "    tweets_cnt = tweets_col.count_documents(myquery)\n",
    "    dist_users = len(tweets_col.distinct('user_id', myquery))\n",
    "\n",
    "    #ave_query =([{\"$group\": {\"_id\":'null', \"average\": {\"$avg\":\"$followers\"} } }])\n",
    "\n",
    "    p =1\n",
    "    avg = 0\n",
    "    for i in mydoc:\n",
    "        avg = avg+i['followers']\n",
    "        p+=1\n",
    "\n",
    "    avg_follow = round(avg/p,0)\n",
    "    mydoc = tweets_col.find(myquery).sort(\"followers\",-1)\n",
    "    \n",
    "    tweet_1 = mydoc[0]['text']\n",
    "    tweet_2 = mydoc[1]['text']\n",
    "    \n",
    "    mydict = {\"tweets_cnt\":tweets_cnt,\"dist_users\":dist_users,\"avg_follow\":avg_follow,\"tweet_1\":tweet_1,\"tweet_2\":tweet_2}\n",
    "    \n",
    "    key = \"hashtag_\"+m\n",
    "    \n",
    "    conn.hmset(key,mydict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching data for 50 most popular users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajuk\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:24: DeprecationWarning: Redis.hmset() is deprecated. Use Redis.hset() instead.\n"
     ]
    }
   ],
   "source": [
    "query =\"select handle from (select handle from user order by followers desc) as b LIMIT 50\"\n",
    "cursor.execute(query)\n",
    "\n",
    "x = cursor.fetchall()\n",
    "top_50 = list(map(lambda x:x[0],x))\n",
    "\n",
    "for i in top_50:\n",
    "\n",
    "    query =\"select user_name,handle,description,followers,statuses,created_date,verified,friends,favourites,protected from user where handle ='{}'\".format(i)\n",
    "    cursor.execute(query)\n",
    "\n",
    "    x = list(cursor.fetchone())\n",
    "    x[5] = datetime.strftime(x[5], '%Y-%m-%d')\n",
    "\n",
    "    myquery = { \"handle\": {\"$eq\":i}}\n",
    "    mydoc = tweets_col.find(myquery).sort(\"time\",-1)\n",
    "    \n",
    "    tweet_1 = mydoc[0]['text']\n",
    "\n",
    "    tweets_cnt = tweets_col.count_documents(myquery)\n",
    "\n",
    "    mydict = {\"user_name\":x[0],\"description\":x[2],\"followers\":x[3],\"statuses\":x[4],\"created_date\":x[5],\"verified\":x[6],\"friends\":x[7],\"favourites\":x[8],\"protected\":x[9],\"tweets_cnt\":tweets_cnt,\"tweet_1\":tweet_1} \n",
    "\n",
    "    conn.hmset(x[1],mydict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TheStreet',\n",
       " 'RobMcNealy',\n",
       " 'OKEx',\n",
       " 'HuobiGlobal',\n",
       " 'kennyflorian',\n",
       " 'DocumentingBTC',\n",
       " 'DogecoinRise',\n",
       " 'maxkeiser',\n",
       " 'BitPay',\n",
       " 'lopp',\n",
       " 'RussellOkung',\n",
       " 'adam3us',\n",
       " 'Sweepsgg',\n",
       " 'CryptoBoomNews',\n",
       " 'jimmysong',\n",
       " 'JeffBooth',\n",
       " 'VinnyLingham',\n",
       " 'PeterMcCormack',\n",
       " 'BeefEnt',\n",
       " 'wallstwolverine',\n",
       " 'JerseyKidPicks',\n",
       " 'BTC_Archive',\n",
       " 'bordong2',\n",
       " 'hentvv',\n",
       " 'pierre_rochard',\n",
       " 'statmuse',\n",
       " 'twobitidiot',\n",
       " 'stacyherbert',\n",
       " 'saifedean',\n",
       " 'GoingParabolic',\n",
       " 'Pentosh1',\n",
       " 'CryptoWendyO',\n",
       " 'lightning',\n",
       " 'defipulse',\n",
       " 'nebraskangooner',\n",
       " 'ThisIsNuse',\n",
       " 'TheCryptoZombie',\n",
       " 'HollowManSeries',\n",
       " 'matt_odell',\n",
       " 'MustHaveCrypto',\n",
       " 'CryptoMatrix2',\n",
       " 'AP4Liberty',\n",
       " 'parabolictrav',\n",
       " 'bmurphypointman',\n",
       " 'LayahHeilpern',\n",
       " 'MattWallace888',\n",
       " 'GoldTelegraph_',\n",
       " 'Bloqport',\n",
       " 'bitstein',\n",
       " 'bitcoinagile']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating functions for the search application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtag(z):\n",
    "    try:\n",
    "        redis_search = \"hashtag_\"+z\n",
    "        \n",
    "        if conn.exists(redis_search):\n",
    "            rec = conn.hgetall(redis_search)\n",
    "            avg_follow=rec['avg_follow']\n",
    "            dist_users=rec['dist_users']\n",
    "            tweets_cnt=rec['tweets_cnt']\n",
    "            tweet_1=rec['tweet_1']\n",
    "            tweet_2=rec['tweet_2']\n",
    "            \n",
    "        else:\n",
    "            myquery = {\"$or\":[{ \"hash_orig\": { \"$elemMatch\": {\"$eq\":z} } },{ \"hash_rtwt\": { \"$elemMatch\": {\"$eq\":z} } }]}\n",
    "            mydoc = tweets_col.find(myquery).sort(\"followers\",-1)\n",
    "\n",
    "            tweets_cnt = tweets_col.count_documents(myquery)\n",
    "            dist_users = len(tweets_col.distinct('user_id', myquery))\n",
    "\n",
    "            #ave_query =([{\"$group\": {\"_id\":'null', \"average\": {\"$avg\":\"$followers\"} } }])\n",
    "\n",
    "            p =1\n",
    "            avg = 0\n",
    "            for i in mydoc:\n",
    "                avg = avg+i['followers']\n",
    "                p+=1\n",
    "\n",
    "            avg_follow = round(avg/p,0)\n",
    "            mydoc = tweets_col.find(myquery).sort(\"followers\",-1)\n",
    "\n",
    "            tweet_1=mydoc[0]['text']\n",
    "            tweet_2=mydoc[1]['text']\n",
    "\n",
    "        text = fontstyle.apply('SUMMARY STATISTICS:', 'bold/white/black_BG')\n",
    "\n",
    "        summary=\"\"\"\n",
    "\n",
    "        Number of tweets: {}\n",
    "\n",
    "        Number of users who posted the hashtag: {}\n",
    "\n",
    "        Average no. of followers for the users who tweeted: {}\n",
    "\n",
    "        \"\"\".format(tweets_cnt,dist_users,avg_follow)\n",
    "\n",
    "\n",
    "        twt_head = fontstyle.apply('Two Tweets from the most followed people ', 'bold/white/black_BG')\n",
    "\n",
    "        tweet = \"\"\"\"\n",
    "\n",
    "        1.{}\n",
    "\n",
    "        2.{}\"\"\".format(tweet_1,tweet_2)\n",
    "\n",
    "\n",
    "        print(text,summary,twt_head,tweet)\n",
    "    except:\n",
    "        error = fontstyle.apply('Use alternate search criteria', 'bold/white/black_BG')\n",
    "        print(error)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user(z):\n",
    "    try:\n",
    "    ###Implementing cache\n",
    "        if conn.exists(z):\n",
    "            x =[None]*10\n",
    "            rec = conn.hgetall(z)\n",
    "            x[0] = rec['user_name'] \n",
    "            x[5] = rec['created_date'] \n",
    "            x[2] = rec['description'] \n",
    "            x[6] = rec['verified'] \n",
    "            x[9] = rec['protected'] \n",
    "            x[3] = rec['followers'] \n",
    "            x[7] = rec['friends'] \n",
    "            x[4] = rec['statuses'] \n",
    "            x[8] = rec['favourites'] \n",
    "\n",
    "            twt = rec['tweet_1']\n",
    "        else:\n",
    "            query =\"select user_name,handle,description,followers,statuses,created_date,verified,friends,favourites,protected from user where handle ='{}'\".format(z)\n",
    "            cursor.execute(query)\n",
    "\n",
    "            x = list(cursor.fetchone())\n",
    "            x[5] = datetime.strftime(x[5], '%Y-%m-%d')\n",
    "\n",
    "            myquery = { \"handle\": {\"$eq\":z}} \n",
    "            mydoc = tweets_col.find(myquery).sort(\"time\",-1)\n",
    "\n",
    "            tweets_cnt = tweets_col.count_documents(myquery)\n",
    "\n",
    "\n",
    "\n",
    "            twt = mydoc[0]['text']\n",
    "\n",
    "        text = fontstyle.apply('SUMMARY STATISTICS:', 'bold/white/black_BG')    \n",
    "        summary=\"\"\"\n",
    "\n",
    "        User Name: '{}'\n",
    "\n",
    "        Created date : {}\n",
    "\n",
    "        Description : '{}'\n",
    "\n",
    "        Verified : '{}'\n",
    "\n",
    "        Protected : '{}'\n",
    "\n",
    "        Followers : {}\n",
    "\n",
    "        Friends : {}\n",
    "\n",
    "        Statuses : {}\n",
    "\n",
    "        Favourites : {}\n",
    "\n",
    "        \"\"\".format(x[0],x[5],x[2],x[6],x[9],x[3],x[7],x[4],x[8])\n",
    "\n",
    "\n",
    "        twt_head = fontstyle.apply('Latest Tweet from the User:', 'bold/white/black_BG')\n",
    "\n",
    "\n",
    "        tweet = \"\"\"\"\n",
    "\n",
    "        1.{}\n",
    "\n",
    "        \"\"\".format(twt)\n",
    "\n",
    "\n",
    "        print(text,summary,twt_head,tweet)\n",
    "    except:\n",
    "        error = fontstyle.apply('Use alternate search criteria', 'bold/white/black_BG')\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_range(minm, maxm):\n",
    "    try:\n",
    "        minm = str(minm)\n",
    "        maxm = str(maxm)\n",
    "        myquery = {\"time\":{\"$gte\":minm,\"$lt\":maxm}}\n",
    "        mydoc = tweets_col.find(myquery).sort(\"followers\",-1)\n",
    "\n",
    "        tweets_cnt = tweets_col.count_documents(myquery)\n",
    "        dist_users = len(tweets_col.distinct('user_id', myquery))\n",
    "\n",
    "        #ave_query =([{\"$group\": {\"_id\":'null', \"average\": {\"$avg\":\"$followers\"} } }])\n",
    "\n",
    "        p =1\n",
    "        avg = 0\n",
    "        for i in mydoc:\n",
    "            avg = avg+i['followers']\n",
    "            p+=1\n",
    "\n",
    "        avg_follow = round(avg/p,0)\n",
    "        mydoc = tweets_col.find(myquery).sort(\"followers\",-1)\n",
    "\n",
    "        text = fontstyle.apply('SUMMARY STATISTICS:', 'bold/white/black_BG')\n",
    "\n",
    "        summary=\"\"\"\n",
    "        \n",
    "        Number of tweets: {}\n",
    "\n",
    "        Number of users who posted within the time range : {}\n",
    "\n",
    "        Average no. of followers for the users who tweeted: {}\n",
    "\n",
    "        \"\"\".format(tweets_cnt,dist_users,avg_follow)\n",
    "\n",
    "\n",
    "        twt_head = fontstyle.apply('2 Tweets from the most followed people ', 'bold/white/black_BG')\n",
    "\n",
    "        tweet = \"\"\"\"\n",
    "\n",
    "        1.{}\n",
    "\n",
    "        2.{}\"\"\".format(mydoc[0]['text'],mydoc[1]['text'])\n",
    "\n",
    "\n",
    "        print(text,summary,twt_head,tweet)\n",
    "    except:\n",
    "        error = fontstyle.apply('Use alternate search criteria', 'bold/white/black_BG')\n",
    "        print(error)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word(z):\n",
    "    try:\n",
    "        myquery = {\"$or\":[{ \"text\": {\"$regex\":z} } ,{ \"rtwt_text\": {\"$regex\":z} } ]}\n",
    "        mydoc = tweets_col.find(myquery).sort(\"followers\",-1)\n",
    "\n",
    "\n",
    "        tweets_cnt = tweets_col.count_documents(myquery)\n",
    "        dist_users = len(tweets_col.distinct('user_id', myquery))\n",
    "\n",
    "        #ave_query =([{\"$group\": {\"_id\":'null', \"average\": {\"$avg\":\"$followers\"} } }])\n",
    "\n",
    "        p =1\n",
    "        avg = 0\n",
    "        for i in mydoc:\n",
    "            avg = avg+i['followers']\n",
    "            p+=1\n",
    "\n",
    "        avg_follow = round(avg/p,0)\n",
    "        mydoc = tweets_col.find(myquery).sort(\"followers\",-1)\n",
    "\n",
    "        text = fontstyle.apply('SUMMARY STATISTICS:', 'bold/white/black_BG')\n",
    "\n",
    "        summary=\"\"\"\n",
    "        \n",
    "        Number of tweets: {}\n",
    "\n",
    "        Number of users who tweeted the selected word : {}\n",
    "\n",
    "        Average no. of followers for the users who tweeted: {}\n",
    "\n",
    "        \"\"\".format(tweets_cnt,dist_users,avg_follow)\n",
    "\n",
    "\n",
    "        twt_head = fontstyle.apply('Two Tweets from the most followed people ', 'bold/white/black_BG')\n",
    "\n",
    "        tweet = \"\"\"\"\n",
    "\n",
    "        1.{}\n",
    "\n",
    "        2.{}\"\"\".format(mydoc[0]['text'],mydoc[1]['text'])\n",
    "\n",
    "\n",
    "        print(text,summary,twt_head,tweet)\n",
    "    except:\n",
    "        error = fontstyle.apply('Use alternate search criteria', 'bold/white/black_BG')\n",
    "        print(error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Search application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adios!\n"
     ]
    }
   ],
   "source": [
    "sig =\"Y\"\n",
    "while sig==\"Y\":\n",
    "    print(\"The attribute you want to search on: hashtag, user, date or word?\")\n",
    "    x =input()\n",
    "    if x=='hashtag':\n",
    "        clear_output()\n",
    "        print(\"what is the hashtag?\")\n",
    "        has = input()\n",
    "        clear_output()\n",
    "        hashtag(has)\n",
    "    if x=='date':\n",
    "        clear_output()\n",
    "        print(\"Enter the from date and to date seperated by a comma in the foramt Y-m-d H:M:S ex: 2021-04-26 14:12:17,2021-04-26 14:12:19 \")\n",
    "        minm, maxm = input().split(\",\")\n",
    "        clear_output()\n",
    "        time_range(minm,maxm)\n",
    "    if x=='user':\n",
    "        clear_output()\n",
    "        print(\"what is the user handle?\")\n",
    "        q = input()\n",
    "        clear_output()\n",
    "        user(q)\n",
    "    if x=='word':\n",
    "        clear_output()\n",
    "        print(\"what is the word?\")\n",
    "        p = input()\n",
    "        clear_output()\n",
    "        word(p)\n",
    "    print(\"Do we want to restart the application (Y/N?)\")\n",
    "    sig = input()\n",
    "    clear_output()\n",
    "print(\"Adios!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance - User search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[40mSUMMARY STATISTICS:\u001b[0m \n",
      "\n",
      "        User Name: 'TheStreet'\n",
      "\n",
      "        Created date : 2008-06-30\n",
      "\n",
      "        Description : 'TheStreet brings you the best business news and premium investing ideas and stock analysis around. We want to help you make money, lots of it.'\n",
      "\n",
      "        Verified : 'True'\n",
      "\n",
      "        Protected : 'False'\n",
      "\n",
      "        Followers : 777506\n",
      "\n",
      "        Friends : 1124\n",
      "\n",
      "        Statuses : 203269\n",
      "\n",
      "        Favourites : 10351\n",
      "\n",
      "         \u001b[1m\u001b[37m\u001b[40mLatest Tweet from the User:\u001b[0m \"\n",
      "\n",
      "        1.A tight end for the Kansas City Chiefs will take his 2021 salary in #bitcoin. https://t.co/QqnFM0HxcA\n",
      "\n",
      "        \n",
      "--- 0.000997304916381836 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "user('TheStreet')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[40mSUMMARY STATISTICS:\u001b[0m \n",
      "\n",
      "        User Name: 'Ankon'\n",
      "\n",
      "        Created date : 2021-04-22\n",
      "\n",
      "        Description : 'Student'\n",
      "\n",
      "        Verified : 'False'\n",
      "\n",
      "        Protected : 'False'\n",
      "\n",
      "        Followers : 1\n",
      "\n",
      "        Friends : 46\n",
      "\n",
      "        Statuses : 43\n",
      "\n",
      "        Favourites : 16\n",
      "\n",
      "         \u001b[1m\u001b[37m\u001b[40mLatest Tweet from the User:\u001b[0m \"\n",
      "\n",
      "        1.RT @Phemex_official: We are giving away $DOGE again! Help our Twitter account to reach 200k followers - a prize pool of up to $40k is waiti…\n",
      "\n",
      "        \n",
      "--- 0.02665090560913086 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "user('ankon99')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance - Hashtag search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[40mSUMMARY STATISTICS:\u001b[0m \n",
      "\n",
      "        Number of tweets: 537\n",
      "\n",
      "        Number of users who posted the hashtag: 397\n",
      "\n",
      "        Average no. of followers for the users who tweeted: 1640.0\n",
      "\n",
      "         \u001b[1m\u001b[37m\u001b[40mTwo Tweets from the most followed people \u001b[0m \"\n",
      "\n",
      "        1.RT @suryocokroo: @latokens When combined into one\n",
      " #DogeOnLatoken strength, of course, it \n",
      "has #strong #market #technology\n",
      "So!\n",
      "there is no…\n",
      "\n",
      "        2.#atlanta #atl #georgia #crypto #cryptocurrency #cryptocurrenices #dogearmy #dogecoin #affiliatemarketing PipeFlare - free #ZEC and #doge #faucet - free games and earn #cryptocoin https://t.co/7tvVbbecvT\n",
      "--- 0.0009629726409912109 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "hashtag('doge')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[40mSUMMARY STATISTICS:\u001b[0m \n",
      "\n",
      "        Number of tweets: 964\n",
      "\n",
      "        Number of users who posted the hashtag: 842\n",
      "\n",
      "        Average no. of followers for the users who tweeted: 2458.0\n",
      "\n",
      "         \u001b[1m\u001b[37m\u001b[40mTwo Tweets from the most followed people \u001b[0m \"\n",
      "\n",
      "        1.RT @HuobiSg: Comment below to cast your vote now! \n",
      "#crypto #Huobi #Bitcoin #Oscars https://t.co/D6gFAEM8fm\n",
      "\n",
      "        2.RT @suryocokroo: @latokens When combined into one\n",
      " #DogeOnLatoken strength, of course, it \n",
      "has #strong #market #technology\n",
      "So!\n",
      "there is no…\n",
      "--- 0.05269312858581543 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "hashtag('crypto')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
